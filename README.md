# ğŸ¤– Local-AI-Voice-Assistant (Llama 3.2 + Faster-Whisper)

A fully offline, privacy-focused voice assistant built with **Python 3.13**. This project integrates a Large Language Model (LLM) for reasoning and a Speech-to-Text (STT) engine to run entirely on local hardware (16GB RAM) without any external API keys or internet connection.

## ğŸš€ Key Features
* **Ears (STT):** Powered by `faster-whisper-base` for real-time, high-accuracy local transcription.
* **Brain (LLM):** Uses `Llama-3.2-3B-Instruct` in GGUF format via `llama-cpp-python` for local reasoning.
* **Mouth (TTS):** Uses `pyttsx3` for fast, offline text-to-speech generation.
* **Privacy First:** All processing happens on-device; no data ever leaves your machine.

---

## ğŸ—ï¸ Project Structure
```text
VoiceAssistantProject/
â”œâ”€â”€ models/             # (Excluded from Git) Stores LLM and STT weights
â”‚   â”œâ”€â”€ faster-whisper-base/
â”‚   â””â”€â”€ llama-3.2-3b-instruct-q4_k_m.gguf
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ears.py         # Microphone and Whisper transcription logic
â”‚   â””â”€â”€ brain.py        # Llama-cpp-python reasoning logic
â”œâ”€â”€ main.py             # Main execution loop (Orchestrator)
â”œâ”€â”€ requirements.txt    # Project dependencies
â””â”€â”€ .gitignore          # Filters out heavy model and environment files